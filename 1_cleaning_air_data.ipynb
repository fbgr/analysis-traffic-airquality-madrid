{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5457c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# import functions made by us\n",
    "import functions\n",
    "\n",
    "# Data is missing from the repository because they had huge sizes (60GB, 1.5GB, 100MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56080f",
   "metadata": {},
   "source": [
    "# Example reading SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5888f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We tried to use SQL with traffic flow and parque2013 but one is too big (60gb in total) and the other\n",
    "# gives un an error, so we'll import in this cell one month from air data just for an example.\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from getpass import getpass  # To get the password without showing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf9082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>H01</th>\n",
       "      <th>V01</th>\n",
       "      <th>...</th>\n",
       "      <th>H20</th>\n",
       "      <th>V20</th>\n",
       "      <th>H21</th>\n",
       "      <th>V21</th>\n",
       "      <th>H22</th>\n",
       "      <th>V22</th>\n",
       "      <th>H23</th>\n",
       "      <th>V23</th>\n",
       "      <th>H24</th>\n",
       "      <th>V24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>079</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2001</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>00020</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>00009</td>\n",
       "      <td>V</td>\n",
       "      <td>00011</td>\n",
       "      <td>V</td>\n",
       "      <td>00018</td>\n",
       "      <td>V</td>\n",
       "      <td>00027</td>\n",
       "      <td>V</td>\n",
       "      <td>00034</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>079</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2001</td>\n",
       "      <td>04</td>\n",
       "      <td>02</td>\n",
       "      <td>00017</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>00012</td>\n",
       "      <td>V</td>\n",
       "      <td>00014</td>\n",
       "      <td>V</td>\n",
       "      <td>00015</td>\n",
       "      <td>V</td>\n",
       "      <td>00013</td>\n",
       "      <td>V</td>\n",
       "      <td>00011</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>079</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2001</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>00011</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>00009</td>\n",
       "      <td>V</td>\n",
       "      <td>00010</td>\n",
       "      <td>V</td>\n",
       "      <td>00011</td>\n",
       "      <td>V</td>\n",
       "      <td>00010</td>\n",
       "      <td>V</td>\n",
       "      <td>00009</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>079</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2001</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>00008</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>00010</td>\n",
       "      <td>V</td>\n",
       "      <td>00010</td>\n",
       "      <td>V</td>\n",
       "      <td>00010</td>\n",
       "      <td>V</td>\n",
       "      <td>00009</td>\n",
       "      <td>V</td>\n",
       "      <td>00008</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>079</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2001</td>\n",
       "      <td>04</td>\n",
       "      <td>05</td>\n",
       "      <td>00008</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>00009</td>\n",
       "      <td>V</td>\n",
       "      <td>00009</td>\n",
       "      <td>V</td>\n",
       "      <td>00011</td>\n",
       "      <td>V</td>\n",
       "      <td>00013</td>\n",
       "      <td>V</td>\n",
       "      <td>00014</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO   ANO MES DIA  \\\n",
       "0         28       079         4         1  28079004_1_38  2001  04  01   \n",
       "1         28       079         4         1  28079004_1_38  2001  04  02   \n",
       "2         28       079         4         1  28079004_1_38  2001  04  03   \n",
       "3         28       079         4         1  28079004_1_38  2001  04  04   \n",
       "4         28       079         4         1  28079004_1_38  2001  04  05   \n",
       "\n",
       "     H01 V01  ...    H20 V20    H21 V21    H22 V22    H23 V23    H24 V24  \n",
       "0  00020   V  ...  00009   V  00011   V  00018   V  00027   V  00034   V  \n",
       "1  00017   V  ...  00012   V  00014   V  00015   V  00013   V  00011   V  \n",
       "2  00011   V  ...  00009   V  00010   V  00011   V  00010   V  00009   V  \n",
       "3  00008   V  ...  00010   V  00010   V  00010   V  00009   V  00008   V  \n",
       "4  00008   V  ...  00009   V  00009   V  00011   V  00013   V  00014   V  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "password = getpass()\n",
    "connection_string = 'mysql+pymysql://root:'+password+'@localhost/aire'\n",
    "engine = create_engine(connection_string)\n",
    "example = pd.read_sql_query('SELECT * FROM abr_mo01', engine)\n",
    "example.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be6161",
   "metadata": {},
   "source": [
    "## Reading air_quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785422a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading air_quality data and concatenating alll the data\n",
    "anios = range(2010,2020)\n",
    "folders = [\"Anio\"+str(anio) for anio in anios]\n",
    "months = [\"ene\",\"feb\",\"mar\",\"abr\",\"may\",\"jun\",\"jul\",\"ago\",\"sep\",\"oct\",\"nov\",\"dic\"]\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for k,folder in enumerate(folders):\n",
    "    months_anio = [months[i]+\"_mo\"+folder[-2:]+\".csv\" for i in range(len(months))]\n",
    "    \n",
    "    for month in months_anio:\n",
    "        new_month = pd.read_csv(\"./air_quality/\"+folder+\"/\"+month,sep=\";\",encoding=\"latin-1\")\n",
    "        all_data = pd.concat([all_data, new_month], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca59376",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7051cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resseting index after the concat\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "# Filtering out stations that are not within zone A+B\n",
    "all_data=all_data[all_data['ESTACION'].isin([38,48,4,35,8,49,47,11,39,50])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2699ce",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f095e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting vector H and V\n",
    "V_haches = ['H01', 'V01', 'H02', 'V02', 'H03', 'V03', 'H04',\n",
    "       'V04', 'H05', 'V05', 'H06', 'V06', 'H07', 'V07', 'H08', 'V08', 'H09',\n",
    "       'V09', 'H10', 'V10', 'H11', 'V11', 'H12', 'V12', 'H13', 'V13', 'H14',\n",
    "       'V14', 'H15', 'V15', 'H16', 'V16', 'H17', 'V17', 'H18', 'V18', 'H19',\n",
    "       'V19', 'H20', 'V20', 'H21', 'V21', 'H22', 'V22', 'H23', 'V23', 'H24','V24']\n",
    "haches = []\n",
    "uves = []\n",
    "for index in range(0,len(V_haches),2):\n",
    "    haches.append(V_haches[index])\n",
    "    uves.append(V_haches[index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e688527",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% completed.\r"
     ]
    }
   ],
   "source": [
    "# Optional ~ Printing options\n",
    "printing = 0\n",
    "updating = 2500\n",
    "\n",
    "# For every row, doing the average across al the values H-XX if V-XX == V, otherwise it means that \n",
    "# measure is not reliable and so we don't count it.\n",
    "for brute_index,row in all_data.iterrows():\n",
    "    count = 0\n",
    "    total = 0\n",
    "    \n",
    "    for index in range(len(uves)):\n",
    "    # for every column VXX we check if it's 'V'\n",
    "        if row[uves[index]]=='V':\n",
    "            count += 1\n",
    "            total += row[haches[index]]\n",
    "    \n",
    "    if count != 0:        \n",
    "        all_data.loc[brute_index,'MEAN'] = total/count\n",
    "    \n",
    "    # If there are no reliable values for that day, write the mean as a None\n",
    "    else:\n",
    "        all_data.loc[brute_index,'MEAN'] = None\n",
    "    \n",
    "    # Optional ~ printing\n",
    "    if (brute_index+1)%updating==0:\n",
    "        printing += updating\n",
    "        print('%.1f%% completed.' %(printing/len(all_data)*100),end='\\r')\n",
    "print('100.0% completed.',end='\\r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787f7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the same magnitud (particle) measurements of different stations\n",
    "all_data = all_data.groupby(['MAGNITUD','ANO','MES','DIA']).agg({'MEAN':np.mean}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27553ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating year-month-day as a single column\n",
    "all_data['FECHA'] = all_data[['ANO','MES','DIA']].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "all_data['FECHA'] = pd.to_datetime(all_data['FECHA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9374ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out every year before 2013\n",
    "all_data=all_data[all_data['FECHA']>='2013-01-01'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ac4e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% completed.\r"
     ]
    }
   ],
   "source": [
    "# Creating a column with the first day of that time-range (we'll use this column later to aggregate by week)\n",
    "all_data = functions.aggregate_time2(all_data,'FECHA',days=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "554a2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by week, magnitud\n",
    "all_data = all_data.groupby(['MAGNITUD','time_range']).agg({'MEAN':np.mean}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c20285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magnitud</th>\n",
       "      <th>time_range</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>7.362202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>5.173782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>6.855948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>6.101359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-03-02</td>\n",
       "      <td>4.555366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>44</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>0.114512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>44</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>0.095403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>44</td>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>0.091150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>44</td>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>0.073052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>44</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>0.150833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      magnitud time_range      mean\n",
       "0            1 2013-01-01  7.362202\n",
       "1            1 2013-01-16  5.173782\n",
       "2            1 2013-01-31  6.855948\n",
       "3            1 2013-02-15  6.101359\n",
       "4            1 2013-03-02  4.555366\n",
       "...        ...        ...       ...\n",
       "2299        44 2019-10-27  0.114512\n",
       "2300        44 2019-11-11  0.095403\n",
       "2301        44 2019-11-26  0.091150\n",
       "2302        44 2019-12-11  0.073052\n",
       "2303        44 2019-12-26  0.150833\n",
       "\n",
       "[2304 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snake_case before saving the data\n",
    "all_data.columns = list(map(lambda x: x.lower(), all_data.columns))\n",
    "all_data.columns = all_data.columns.str.replace(' ','_')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7fe563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results \n",
    "all_data.to_csv('./air_quality/clean_air.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
